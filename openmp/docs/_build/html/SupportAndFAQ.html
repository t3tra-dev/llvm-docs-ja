<!DOCTYPE html>

<html lang="en" data-content_root="./">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Support, Getting Involved, and FAQ &#8212; LLVM/OpenMP  documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=d75fae25" />
    <link rel="stylesheet" type="text/css" href="_static/agogo.css?v=a323ad78" />
    <script src="_static/documentation_options.js?v=7f41d439"></script>
    <script src="_static/doctools.js?v=888ff710"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="OpenMP 21.0.0 Release Notes" href="ReleaseNotes.html" />
    <link rel="prev" title="OpenMP Command-Line Argument Reference" href="CommandLineArgumentReference.html" />
<style type="text/css">
  table.right { float: right; margin-left: 20px; }
  table.right td { border: 1px solid #ccc; }
</style>

  </head><body>
    <div class="header-wrapper" role="banner">
      <div class="header">
        <div class="headertitle"><a
          href="index.html">LLVM/OpenMP  documentation</a></div>
        <div class="rel" role="navigation" aria-label="related navigation">
          <a href="index.html" title="LLVM OpenMP Documentation">HOME</a>
           |
          <a href="CommandLineArgumentReference.html" title="OpenMP Command-Line Argument Reference"
             accesskey="P">previous</a> |
          <a href="ReleaseNotes.html" title="OpenMP 21.0.0 Release Notes"
             accesskey="N">next</a> |
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a>
        </div>
       </div>
    </div>

    <div class="content-wrapper">
      <div class="content">
        <div class="document">
            
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="support-getting-involved-and-faq">
<h1>Support, Getting Involved, and FAQ<a class="headerlink" href="#support-getting-involved-and-faq" title="Link to this heading">¶</a></h1>
<p>Please do not hesitate to reach out to us on the <a class="reference external" href="https://discourse.llvm.org/c/runtimes/openmp/35">Discourse forums (Runtimes - OpenMP)</a> or join
one of our <a class="reference internal" href="#calls"><span class="std std-ref">regular calls</span></a>. Some common questions are answered in
the <a class="reference internal" href="#faq"><span class="std std-ref">FAQ</span></a>.</p>
<section id="calls">
<span id="id1"></span><h2>Calls<a class="headerlink" href="#calls" title="Link to this heading">¶</a></h2>
<section id="openmp-in-llvm-technical-call">
<h3>OpenMP in LLVM Technical Call<a class="headerlink" href="#openmp-in-llvm-technical-call" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p>Development updates on OpenMP (and OpenACC) in the LLVM Project, including Clang, optimization, and runtime work.</p></li>
<li><p>Join <a class="reference external" href="https://bluejeans.com/544112769//webrtc">OpenMP in LLVM Technical Call</a>.</p></li>
<li><p>Time: Weekly call on every Wednesday 7:00 AM Pacific time.</p></li>
<li><p>Meeting minutes are <a class="reference external" href="https://docs.google.com/document/d/1Tz8WFN13n7yJ-SCE0Qjqf9LmjGUw0dWO9Ts1ss4YOdg/edit">here</a>.</p></li>
<li><p>Status tracking <a class="reference external" href="https://openmp.llvm.org/docs">page</a>.</p></li>
</ul>
</section>
<section id="openmp-in-flang-technical-call">
<h3>OpenMP in Flang Technical Call<a class="headerlink" href="#openmp-in-flang-technical-call" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p>Development updates on OpenMP and OpenACC in the Flang Project.</p></li>
<li><p>Join <a class="reference external" href="https://bit.ly/39eQW3o">OpenMP in Flang Technical Call</a></p></li>
<li><p>Time: Weekly call on every Thursdays 8:00 AM Pacific time.</p></li>
<li><p>Meeting minutes are <a class="reference external" href="https://docs.google.com/document/d/1yA-MeJf6RYY-ZXpdol0t7YoDoqtwAyBhFLr5thu5pFI">here</a>.</p></li>
<li><p>Status tracking <a class="reference external" href="https://docs.google.com/spreadsheets/d/1FvHPuSkGbl4mQZRAwCIndvQx9dQboffiD-xD0oqxgU0/edit#gid=0">page</a>.</p></li>
</ul>
</section>
</section>
<section id="faq">
<span id="id3"></span><h2>FAQ<a class="headerlink" href="#faq" title="Link to this heading">¶</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The FAQ is a work in progress and most of the expected content is not
yet available. While you can expect changes, we always welcome feedback and
additions. Please post on the <a class="reference external" href="https://discourse.llvm.org/c/runtimes/openmp/35">Discourse forums (Runtimes - OpenMP)</a>.</p>
</div>
<section id="q-how-to-contribute-a-patch-to-the-webpage-or-any-other-part">
<h3>Q: How to contribute a patch to the webpage or any other part?<a class="headerlink" href="#q-how-to-contribute-a-patch-to-the-webpage-or-any-other-part" title="Link to this heading">¶</a></h3>
<p>All patches go through the regular <a class="reference external" href="https://llvm.org/docs/Contributing.html#how-to-submit-a-patch">LLVM review process</a>.</p>
</section>
<section id="q-how-to-build-an-openmp-gpu-offload-capable-compiler">
<span id="build-offload-capable-compiler"></span><h3>Q: How to build an OpenMP GPU offload capable compiler?<a class="headerlink" href="#q-how-to-build-an-openmp-gpu-offload-capable-compiler" title="Link to this heading">¶</a></h3>
<p>The easiest way to create an offload capable compiler is to use the provided
CMake cache file. This will enable the projects and runtimes necessary for
offloading as well as some extra options.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$&gt;<span class="w"> </span><span class="nb">cd</span><span class="w"> </span>llvm-project<span class="w">  </span><span class="c1"># The llvm-project checkout</span>
$&gt;<span class="w"> </span>mkdir<span class="w"> </span>build
$&gt;<span class="w"> </span><span class="nb">cd</span><span class="w"> </span>build
$&gt;<span class="w"> </span>cmake<span class="w"> </span>../llvm<span class="w"> </span>-G<span class="w"> </span>Ninja<span class="w">                                                 </span><span class="se">\</span>
<span class="w">   </span>-C<span class="w"> </span>../offload/cmake/caches/Offload.cmake<span class="w"> </span><span class="se">\ </span><span class="c1"># The preset cache file</span>
<span class="w">   </span>-DCMAKE_BUILD_TYPE<span class="o">=</span>&lt;Debug<span class="p">|</span>Release&gt;<span class="w">   </span><span class="se">\ </span><span class="c1"># Select build type</span>
<span class="w">   </span>-DCMAKE_INSTALL_PREFIX<span class="o">=</span>&lt;PATH&gt;<span class="w">        </span><span class="se">\ </span><span class="c1"># Where the libraries will live</span>
$&gt;<span class="w"> </span>ninja<span class="w"> </span>install
</pre></div>
</div>
<p>To manually build an <em>effective</em> OpenMP offload capable compiler, only one extra CMake
option, <code class="docutils literal notranslate"><span class="pre">LLVM_ENABLE_RUNTIMES=&quot;openmp;offload&quot;</span></code>, is needed when building LLVM (Generic
information about building LLVM is available <a class="reference external" href="https://llvm.org/docs/GettingStarted.html">here</a>.). Make sure all backends that
are targeted by OpenMP are enabled. That can be done by adjusting the CMake
option <code class="docutils literal notranslate"><span class="pre">LLVM_TARGETS_TO_BUILD</span></code>. The corresponding targets for offloading to AMD
and Nvidia GPUs are <code class="docutils literal notranslate"><span class="pre">&quot;AMDGPU&quot;</span></code> and <code class="docutils literal notranslate"><span class="pre">&quot;NVPTX&quot;</span></code>, respectively. By default,
Clang will be built with all backends enabled. When building with
<code class="docutils literal notranslate"><span class="pre">LLVM_ENABLE_RUNTIMES=&quot;openmp&quot;</span></code> OpenMP should not be enabled in
<code class="docutils literal notranslate"><span class="pre">LLVM_ENABLE_PROJECTS</span></code> because it is enabled by default.</p>
<p>For Nvidia offload, please see <a class="reference internal" href="#build-nvidia-offload-capable-compiler"><span class="std std-ref">Q: How to build an OpenMP Nvidia offload capable compiler?</span></a>.
For AMDGPU offload, please see <a class="reference internal" href="#build-amdgpu-offload-capable-compiler"><span class="std std-ref">Q: How to build an OpenMP AMDGPU offload capable compiler?</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The compiler that generates the offload code should be the same (version) as
the compiler that builds the OpenMP device runtimes. The OpenMP host runtime
can be built by a different compiler.</p>
</div>
</section>
<section id="q-how-to-build-an-openmp-nvidia-offload-capable-compiler">
<span id="build-nvidia-offload-capable-compiler"></span><h3>Q: How to build an OpenMP Nvidia offload capable compiler?<a class="headerlink" href="#q-how-to-build-an-openmp-nvidia-offload-capable-compiler" title="Link to this heading">¶</a></h3>
<p>The CUDA SDK is required on the machine that will build and execute the
offloading application. Normally this is only required at runtime by dynamically
opening the CUDA driver API. This can be disabled in the build by omitting
<code class="docutils literal notranslate"><span class="pre">cuda</span></code> from the <code class="docutils literal notranslate"><span class="pre">LIBOMPTARGET_DLOPEN_PLUGINS</span></code> list which is present by
default. With this setting we will instead find the CUDA library at LLVM build
time and link against it directly.</p>
</section>
<section id="q-how-to-build-an-openmp-amdgpu-offload-capable-compiler">
<span id="build-amdgpu-offload-capable-compiler"></span><h3>Q: How to build an OpenMP AMDGPU offload capable compiler?<a class="headerlink" href="#q-how-to-build-an-openmp-amdgpu-offload-capable-compiler" title="Link to this heading">¶</a></h3>
<p>The OpenMP AMDGPU offloading support depends on the ROCm math libraries and the
HSA ROCr / ROCt runtimes. These are normally provided by a standard ROCm
installation, but can be built and used independently if desired. Building the
libraries does not depend on these libraries by default by dynamically loading
the HSA runtime at program execution. As in the CUDA case, this can be change by
omitting <code class="docutils literal notranslate"><span class="pre">amdgpu</span></code> from the <code class="docutils literal notranslate"><span class="pre">LIBOMPTARGET_DLOPEN_PLUGINS</span></code> list.</p>
</section>
<section id="q-what-are-the-known-limitations-of-openmp-amdgpu-offload">
<h3>Q: What are the known limitations of OpenMP AMDGPU offload?<a class="headerlink" href="#q-what-are-the-known-limitations-of-openmp-amdgpu-offload" title="Link to this heading">¶</a></h3>
<p>LD_LIBRARY_PATH or rpath/runpath are required to find libomp.so and
libomptarget.so correctly. The recommended way to configure this is with the
<code class="docutils literal notranslate"><span class="pre">-frtlib-add-rpath</span></code> option. Alternatively, set the <code class="docutils literal notranslate"><span class="pre">LD_LIBRARY_PATH</span></code>
environment variable to point to the installation. Normally, these libraries are
installed in the target specific runtime directory. For example, a typical
installation will have
<code class="docutils literal notranslate"><span class="pre">&lt;install&gt;/lib/x86_64-unknown-linux-gnu/llibomptarget.so</span></code></p>
<p>Some versions of the driver for the radeon vii (gfx906) will error unless the
environment variable ‘export HSA_IGNORE_SRAMECC_MISREPORT=1’ is set.</p>
</section>
<section id="q-what-are-the-llvm-components-used-in-offloading-and-how-are-they-found">
<h3>Q: What are the LLVM components used in offloading and how are they found?<a class="headerlink" href="#q-what-are-the-llvm-components-used-in-offloading-and-how-are-they-found" title="Link to this heading">¶</a></h3>
<p>The libraries used by an executable compiled for target offloading are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">libomp.so</span></code> (or similar), the host openmp runtime</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">libomptarget.so</span></code>, the target-agnostic target offloading openmp runtime</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">libompdevice.a</span></code>, the device-side OpenMP runtime.</p></li>
<li><p>dependencies of those plugins, e.g. cuda/rocr for nvptx/amdgpu</p></li>
</ul>
<p>The compiled executable is dynamically linked against a host runtime, e.g.
<code class="docutils literal notranslate"><span class="pre">libomp.so</span></code>, and against the target offloading runtime, <code class="docutils literal notranslate"><span class="pre">libomptarget.so</span></code>. These
are found like any other dynamic library, by setting rpath or runpath on the
executable, by setting <code class="docutils literal notranslate"><span class="pre">LD_LIBRARY_PATH</span></code>, or by adding them to the system search.</p>
<p><code class="docutils literal notranslate"><span class="pre">libomptarget.so</span></code> is only supported to work with the associated <code class="docutils literal notranslate"><span class="pre">clang</span></code>
compiler. On systems with globally installed <code class="docutils literal notranslate"><span class="pre">libomptarget.so</span></code> this can be
problematic. For this reason it is recommended to use a <a class="reference external" href="https://clang.llvm.org/docs/UsersManual.html#configuration-files">Clang configuration
file</a> to
automatically configure the environment. For example, store the following file
as <code class="docutils literal notranslate"><span class="pre">openmp.cfg</span></code> next to your <code class="docutils literal notranslate"><span class="pre">clang</span></code> executable.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span># Library paths for OpenMP offloading.
-L &#39;&lt;CFGDIR&gt;/../lib&#39;
-Wl,-rpath=&#39;&lt;CFGDIR&gt;/../lib&#39;
</pre></div>
</div>
<p>The plugins will try to find their dependencies in plugin-dependent fashion.</p>
<p>The cuda plugin is dynamically linked against libcuda if cmake found it at
compiler build time. Otherwise it will attempt to dlopen <code class="docutils literal notranslate"><span class="pre">libcuda.so</span></code>. It does
not have rpath set.</p>
<p>The amdgpu plugin is linked against ROCr if cmake found it at compiler build
time. Otherwise it will attempt to dlopen <code class="docutils literal notranslate"><span class="pre">libhsa-runtime64.so</span></code>. It has rpath
set to <code class="docutils literal notranslate"><span class="pre">$ORIGIN</span></code>, so installing <code class="docutils literal notranslate"><span class="pre">libhsa-runtime64.so</span></code> in the same directory is a
way to locate it without environment variables.</p>
<p>In addition to those, there is a compiler runtime library called deviceRTL.
This is compiled from mostly common code into an architecture specific
bitcode library, e.g. <code class="docutils literal notranslate"><span class="pre">libomptarget-nvptx-sm_70.bc</span></code>.</p>
<p>Clang and the deviceRTL need to match closely as the interface between them
changes frequently. Using both from the same monorepo checkout is strongly
recommended.</p>
<p>Unlike the host side which lets environment variables select components, the
deviceRTL that is located in the clang lib directory is preferred. Only if
it is absent, the <code class="docutils literal notranslate"><span class="pre">LIBRARY_PATH</span></code> environment variable is searched to find a
bitcode file with the right name. This can be overridden by passing a clang
flag, <code class="docutils literal notranslate"><span class="pre">--libomptarget-nvptx-bc-path</span></code> or <code class="docutils literal notranslate"><span class="pre">--libomptarget-amdgcn-bc-path</span></code>. That
can specify a directory or an exact bitcode file to use.</p>
</section>
<section id="q-does-openmp-offloading-support-work-in-pre-packaged-llvm-releases">
<h3>Q: Does OpenMP offloading support work in pre-packaged LLVM releases?<a class="headerlink" href="#q-does-openmp-offloading-support-work-in-pre-packaged-llvm-releases" title="Link to this heading">¶</a></h3>
<p>For now, the answer is most likely <em>no</em>. Please see <a class="reference internal" href="#build-offload-capable-compiler"><span class="std std-ref">Q: How to build an OpenMP GPU offload capable compiler?</span></a>.</p>
</section>
<section id="q-does-openmp-offloading-support-work-in-packages-distributed-as-part-of-my-os">
<h3>Q: Does OpenMP offloading support work in packages distributed as part of my OS?<a class="headerlink" href="#q-does-openmp-offloading-support-work-in-packages-distributed-as-part-of-my-os" title="Link to this heading">¶</a></h3>
<p>For now, the answer is most likely <em>no</em>. Please see <a class="reference internal" href="#build-offload-capable-compiler"><span class="std std-ref">Q: How to build an OpenMP GPU offload capable compiler?</span></a>.</p>
</section>
<section id="q-does-clang-support-math-h-and-complex-h-operations-in-openmp-target-on-gpus">
<span id="math-and-complex-in-target-regions"></span><h3>Q: Does Clang support <cite>&lt;math.h&gt;</cite> and <cite>&lt;complex.h&gt;</cite> operations in OpenMP target on GPUs?<a class="headerlink" href="#q-does-clang-support-math-h-and-complex-h-operations-in-openmp-target-on-gpus" title="Link to this heading">¶</a></h3>
<p>Yes, LLVM/Clang allows math functions and complex arithmetic inside of OpenMP
target regions that are compiled for GPUs.</p>
<p>Clang provides a set of wrapper headers that are found first when <cite>math.h</cite> and
<cite>complex.h</cite>, for C, <cite>cmath</cite> and <cite>complex</cite>, for C++, or similar headers are
included by the application. These wrappers will eventually include the system
version of the corresponding header file after setting up a target device
specific environment. The fact that the system header is included is important
because they differ based on the architecture and operating system and may
contain preprocessor, variable, and function definitions that need to be
available in the target region regardless of the targeted device architecture.
However, various functions may require specialized device versions, e.g.,
<cite>sin</cite>, and others are only available on certain devices, e.g., <cite>__umul64hi</cite>. To
provide “native” support for math and complex on the respective architecture,
Clang will wrap the “native” math functions, e.g., as provided by the device
vendor, in an OpenMP begin/end declare variant. These functions will then be
picked up instead of the host versions while host only variables and function
definitions are still available. Complex arithmetic and functions are support
through a similar mechanism. It is worth noting that this support requires
<a class="reference external" href="https://clang.llvm.org/docs/AttributeReference.html#pragma-omp-declare-variant">extensions to the OpenMP begin/end declare variant context selector</a>
that are exposed through LLVM/Clang to the user as well.</p>
</section>
<section id="q-can-i-use-dynamically-linked-libraries-with-openmp-offloading">
<h3>Q: Can I use dynamically linked libraries with OpenMP offloading?<a class="headerlink" href="#q-can-i-use-dynamically-linked-libraries-with-openmp-offloading" title="Link to this heading">¶</a></h3>
<p>Dynamically linked libraries can be used if there is no device code shared
between the library and application. Anything declared on the device inside the
shared library will not be visible to the application when it’s linked. This is
because device code only supports static linking.</p>
</section>
<section id="q-how-to-build-an-openmp-offload-capable-compiler-with-an-outdated-host-compiler">
<h3>Q: How to build an OpenMP offload capable compiler with an outdated host compiler?<a class="headerlink" href="#q-how-to-build-an-openmp-offload-capable-compiler-with-an-outdated-host-compiler" title="Link to this heading">¶</a></h3>
<p>Enabling the OpenMP runtime will perform a two-stage build for you.
If your host compiler is different from your system-wide compiler, you may need
to set <code class="docutils literal notranslate"><span class="pre">CMAKE_{C,CXX}_FLAGS</span></code> like
<code class="docutils literal notranslate"><span class="pre">--gcc-install-dir=/usr/lib/gcc/x86_64-linux-gnu/12</span></code> so that clang will be
able to find the correct GCC toolchain in the second stage of the build.</p>
<p>For example, if your system-wide GCC installation is too old to build LLVM and
you would like to use a newer GCC, set <code class="docutils literal notranslate"><span class="pre">--gcc-install-dir=</span></code>
to inform clang of the GCC installation you would like to use in the second stage.</p>
</section>
<section id="q-what-does-stack-size-for-entry-function-cannot-be-statically-determined-mean">
<h3>Q: What does ‘Stack size for entry function cannot be statically determined’ mean?<a class="headerlink" href="#q-what-does-stack-size-for-entry-function-cannot-be-statically-determined-mean" title="Link to this heading">¶</a></h3>
<p>This is a warning that the Nvidia tools will sometimes emit if the offloading
region is too complex. Normally, the CUDA tools attempt to statically determine
how much stack memory each thread. This way when the kernel is launched each
thread will have as much memory as it needs. If the control flow of the kernel
is too complex, containing recursive calls or nested parallelism, this analysis
can fail. If this warning is triggered it means that the kernel may run out of
stack memory during execution and crash. The environment variable
<code class="docutils literal notranslate"><span class="pre">LIBOMPTARGET_STACK_SIZE</span></code> can be used to increase the stack size if this
occurs.</p>
</section>
<section id="q-can-openmp-offloading-compile-for-multiple-architectures">
<h3>Q: Can OpenMP offloading compile for multiple architectures?<a class="headerlink" href="#q-can-openmp-offloading-compile-for-multiple-architectures" title="Link to this heading">¶</a></h3>
<p>Since LLVM version 15.0, OpenMP offloading supports offloading to multiple
architectures at once. This allows for executables to be run on different
targets, such as offloading to AMD and NVIDIA GPUs simultaneously, as well as
multiple sub-architectures for the same target. Additionally, static libraries
will only extract archive members if an architecture is used, allowing users to
create generic libraries.</p>
<p>The architecture can either be specified manually using <code class="docutils literal notranslate"><span class="pre">--offload-arch=</span></code>. If
<code class="docutils literal notranslate"><span class="pre">--offload-arch=</span></code> is present and no <code class="docutils literal notranslate"><span class="pre">-fopenmp-targets=</span></code> flag is present then
the targets will be inferred from the architectures. Conversely, if
<code class="docutils literal notranslate"><span class="pre">--fopenmp-targets=</span></code> is present with no <code class="docutils literal notranslate"><span class="pre">--offload-arch</span></code> then the target
architecture will be set to a default value, usually the architecture supported
by the system LLVM was built on by executing the <code class="docutils literal notranslate"><span class="pre">offload-arch</span></code> utility.</p>
<p>For example, an executable can be built that runs on AMDGPU and NVIDIA hardware
given that the necessary build tools are installed for both.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>clang<span class="w"> </span>example.c<span class="w"> </span>-fopenmp<span class="w"> </span>--offload-arch<span class="o">=</span>gfx90a<span class="w"> </span>--offload-arch<span class="o">=</span>sm_80
</pre></div>
</div>
<p>If just given the architectures we should be able to infer the triples,
otherwise we can specify them manually.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>clang<span class="w"> </span>example.c<span class="w"> </span>-fopenmp<span class="w"> </span>-fopenmp-targets<span class="o">=</span>amdgcn-amd-amdhsa,nvptx64-nvidia-cuda<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>-Xopenmp-target<span class="o">=</span>amdgcn-amd-amdhsa<span class="w"> </span>--offload-arch<span class="o">=</span>gfx90a<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>-Xopenmp-target<span class="o">=</span>nvptx64-nvidia-cuda<span class="w"> </span>--offload-arch<span class="o">=</span>sm_80
</pre></div>
</div>
<p>When linking against a static library that contains device code for multiple
architectures, only the images used by the executable will be extracted.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>clang<span class="w"> </span>example.c<span class="w"> </span>-fopenmp<span class="w"> </span>--offload-arch<span class="o">=</span>gfx90a,gfx90a,sm_70,sm_80<span class="w"> </span>-c
llvm-ar<span class="w"> </span>rcs<span class="w"> </span>libexample.a<span class="w"> </span>example.o
clang<span class="w"> </span>app.c<span class="w"> </span>-fopenmp<span class="w"> </span>--offload-arch<span class="o">=</span>gfx90a<span class="w"> </span>-o<span class="w"> </span>app
</pre></div>
</div>
<p>The supported device images can be viewed using the <code class="docutils literal notranslate"><span class="pre">--offloading</span></code> option with
<code class="docutils literal notranslate"><span class="pre">llvm-objdump</span></code>.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>clang<span class="w"> </span>example.c<span class="w"> </span>-fopenmp<span class="w"> </span>--offload-arch<span class="o">=</span>gfx90a<span class="w"> </span>--offload-arch<span class="o">=</span>sm_80<span class="w"> </span>-o<span class="w"> </span>example
llvm-objdump<span class="w"> </span>--offloading<span class="w"> </span>example

a.out:<span class="w">  </span>file<span class="w"> </span>format<span class="w"> </span>elf64-x86-64

OFFLOADING<span class="w"> </span>IMAGE<span class="w"> </span><span class="o">[</span><span class="m">0</span><span class="o">]</span>:
kind<span class="w">            </span>elf
arch<span class="w">            </span>gfx90a
triple<span class="w">          </span>amdgcn-amd-amdhsa
producer<span class="w">        </span>openmp

OFFLOADING<span class="w"> </span>IMAGE<span class="w"> </span><span class="o">[</span><span class="m">1</span><span class="o">]</span>:
kind<span class="w">            </span>elf
arch<span class="w">            </span>sm_80
triple<span class="w">          </span>nvptx64-nvidia-cuda
producer<span class="w">        </span>openmp
</pre></div>
</div>
</section>
<section id="q-can-i-link-openmp-offloading-with-cuda-or-hip">
<h3>Q: Can I link OpenMP offloading with CUDA or HIP?<a class="headerlink" href="#q-can-i-link-openmp-offloading-with-cuda-or-hip" title="Link to this heading">¶</a></h3>
<p>OpenMP offloading files can currently be experimentally linked with CUDA and HIP
files. This will allow OpenMP to call a CUDA device function or vice-versa.
However, the global state will be distinct between the two images at runtime.
This means any global variables will potentially have different values when
queried from OpenMP or CUDA.</p>
<p>Linking CUDA and HIP currently requires enabling a different compilation mode
for CUDA / HIP with <code class="docutils literal notranslate"><span class="pre">--offload-new-driver</span></code> and to link using
<code class="docutils literal notranslate"><span class="pre">--offload-link</span></code>. Additionally, <code class="docutils literal notranslate"><span class="pre">-fgpu-rdc</span></code> must be used to create a
linkable device image.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>clang++<span class="w"> </span>openmp.cpp<span class="w"> </span>-fopenmp<span class="w"> </span>--offload-arch<span class="o">=</span>sm_80<span class="w"> </span>-c
clang++<span class="w"> </span>cuda.cu<span class="w"> </span>--offload-new-driver<span class="w"> </span>--offload-arch<span class="o">=</span>sm_80<span class="w"> </span>-fgpu-rdc<span class="w"> </span>-c
clang++<span class="w"> </span>openmp.o<span class="w"> </span>cuda.o<span class="w"> </span>--offload-link<span class="w"> </span>-o<span class="w"> </span>app
</pre></div>
</div>
</section>
<section id="q-are-libomptarget-and-plugins-backward-compatible">
<h3>Q: Are libomptarget and plugins backward compatible?<a class="headerlink" href="#q-are-libomptarget-and-plugins-backward-compatible" title="Link to this heading">¶</a></h3>
<p>No. libomptarget and plugins are now built as LLVM libraries starting from LLVM
15. Because LLVM libraries are not backward compatible, libomptarget and plugins
are not as well. Given that fact, the interfaces between 1) the Clang compiler
and libomptarget, 2) the Clang compiler and device runtime library, and
3) libomptarget and plugins are not guaranteed to be compatible with an earlier
version. Users are responsible for ensuring compatibility when not using the
Clang compiler and runtime libraries from the same build. Nevertheless, in order
to better support third-party libraries and toolchains that depend on existing
libomptarget entry points, contributors are discouraged from making
modifications to them.</p>
</section>
<section id="q-can-i-use-libc-functions-on-the-gpu">
<h3>Q: Can I use libc functions on the GPU?<a class="headerlink" href="#q-can-i-use-libc-functions-on-the-gpu" title="Link to this heading">¶</a></h3>
<p>LLVM provides basic <code class="docutils literal notranslate"><span class="pre">libc</span></code> functionality through the LLVM C Library. For
building instructions, refer to the associated <a class="reference external" href="https://libc.llvm.org/gpu/using.html#building-the-gpu-library">LLVM libc documentation</a>. Once built,
this provides a static library called <code class="docutils literal notranslate"><span class="pre">libcgpu.a</span></code>. See the documentation for a
list of <a class="reference external" href="https://libc.llvm.org/gpu/support.html">supported functions</a> as well.
To utilize these functions, simply link this library as any other when building
with OpenMP.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>clang++<span class="w"> </span>openmp.cpp<span class="w"> </span>-fopenmp<span class="w"> </span>--offload-arch<span class="o">=</span>gfx90a<span class="w"> </span>-Xoffload-linker<span class="w"> </span>-lc
</pre></div>
</div>
<p>For more information on how this is implemented in LLVM/OpenMP’s offloading
runtime, refer to the <a class="reference external" href="libomptarget_libc">runtime documentation</a>.</p>
</section>
<section id="q-what-command-line-options-can-i-use-for-openmp">
<h3>Q: What command line options can I use for OpenMP?<a class="headerlink" href="#q-what-command-line-options-can-i-use-for-openmp" title="Link to this heading">¶</a></h3>
<p>We recommend taking a look at the OpenMP
<a class="reference internal" href="CommandLineArgumentReference.html"><span class="doc">command line argument reference</span></a> page.</p>
</section>
<section id="q-can-i-build-the-offloading-runtimes-without-cuda-or-hsa">
<h3>Q: Can I build the offloading runtimes without CUDA or HSA?<a class="headerlink" href="#q-can-i-build-the-offloading-runtimes-without-cuda-or-hsa" title="Link to this heading">¶</a></h3>
<p>By default, the offloading runtime will load the associated vendor runtime
during initialization rather than directly linking against them. This allows the
program to be built and run on many machine. If you wish to directly link
against these libraries, use the <code class="docutils literal notranslate"><span class="pre">LIBOMPTARGET_DLOPEN_PLUGINS=&quot;&quot;</span></code> option to
suppress it for each plugin. The default value is every plugin enabled with
<code class="docutils literal notranslate"><span class="pre">LIBOMPTARGET_PLUGINS_TO_BUILD</span></code>.</p>
</section>
<section id="q-why-is-my-build-taking-a-long-time">
<h3>Q: Why is my build taking a long time?<a class="headerlink" href="#q-why-is-my-build-taking-a-long-time" title="Link to this heading">¶</a></h3>
<p>When installing OpenMP and other LLVM components, the build time on multicore
systems can be significantly reduced with parallel build jobs. As suggested in
<em>LLVM Techniques, Tips, and Best Practices</em>, one could consider using <code class="docutils literal notranslate"><span class="pre">ninja</span></code> as the
generator. This can be done with the CMake option <code class="docutils literal notranslate"><span class="pre">cmake</span> <span class="pre">-G</span> <span class="pre">Ninja</span></code>. Afterward,
use <code class="docutils literal notranslate"><span class="pre">ninja</span> <span class="pre">install</span></code> and specify the number of parallel jobs with <code class="docutils literal notranslate"><span class="pre">-j</span></code>. The build
time can also be reduced by setting the build type to <code class="docutils literal notranslate"><span class="pre">Release</span></code> with the
<code class="docutils literal notranslate"><span class="pre">CMAKE_BUILD_TYPE</span></code> option. Recompilation can also be sped up by caching previous
compilations. Consider enabling <code class="docutils literal notranslate"><span class="pre">Ccache</span></code> with
<code class="docutils literal notranslate"><span class="pre">CMAKE_CXX_COMPILER_LAUNCHER=ccache</span></code>.</p>
</section>
<section id="q-did-this-faq-not-answer-your-question">
<h3>Q: Did this FAQ not answer your question?<a class="headerlink" href="#q-did-this-faq-not-answer-your-question" title="Link to this heading">¶</a></h3>
<p>Feel free to post questions or browse old threads at
<a class="reference external" href="https://discourse.llvm.org/c/runtimes/openmp/">LLVM Discourse</a>.</p>
</section>
</section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
        </div>
        <div class="sidebar">
          
          <h3>Table of Contents</h3>
          <ul>
<li class="toctree-l1"><a class="reference internal" href="index.html">LLVM/OpenMP Documentation</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="design/Overview.html">OpenMP in LLVM — Design Overview</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="openacc/Overview.html">OpenACC Support</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="optimizations/Overview.html">OpenMP Optimizations in LLVM</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="remarks/OptimizationRemarks.html">OpenMP Optimization Remarks</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="CommandLineArgumentReference.html">OpenMP Command-Line Argument Reference</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Support, Getting Involved, and FAQ</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="ReleaseNotes.html">In-Progress ReleaseNotes</a></li>
</ul>

          <div role="search">
            <h3 style="margin-top: 1.5em;">Search</h3>
            <form class="search" action="search.html" method="get">
                <input type="text" name="q" />
                <input type="submit" value="Go" />
            </form>
          </div>

        </div>
        <div class="clearer"></div>
      </div>
    </div>

    <div class="footer-wrapper">
      <div class="footer">
        <div class="left">
          <div role="navigation" aria-label="related navigaton">
            <a href="index.html" title="LLVM OpenMP Documentation">HOME</a>
             |
            <a href="CommandLineArgumentReference.html" title="OpenMP Command-Line Argument Reference"
              >previous</a> |
            <a href="ReleaseNotes.html" title="OpenMP 21.0.0 Release Notes"
              >next</a> |
            <a href="genindex.html" title="General Index"
              >index</a>
          </div>
          <div role="note" aria-label="source link">
          </div>
        </div>

        <div class="right">
          
    <div class="footer" role="contentinfo">
    &#169; Copyright 2013-2025, LLVM/OpenMP.
      Last updated on 2025-08-13.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6.
    </div>
        </div>
        <div class="clearer"></div>
      </div>
    </div>

  </body>
</html>