<!DOCTYPE html>

<html lang="en" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Remote Procedure Calls &#8212; The LLVM C Library</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=d75fae25" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css?v=2e637bd6" />
    <script src="../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Testing the GPU C library" href="testing.html" />
    <link rel="prev" title="Supported Functions" href="support.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="remote-procedure-calls">
<span id="libc-gpu-rpc"></span><h1>Remote Procedure Calls<a class="headerlink" href="#remote-procedure-calls" title="Link to this heading">¶</a></h1>
<nav class="contents local" id="table-of-contents">
<p class="topic-title">Table of Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#remote-procedure-call-implementation" id="id1">Remote Procedure Call Implementation</a></p>
<ul>
<li><p><a class="reference internal" href="#client-example" id="id2">Client Example</a></p></li>
<li><p><a class="reference internal" href="#server-example" id="id3">Server Example</a></p></li>
<li><p><a class="reference internal" href="#cuda-server-example" id="id4">CUDA Server Example</a></p></li>
<li><p><a class="reference internal" href="#extensions" id="id5">Extensions</a></p></li>
</ul>
</li>
</ul>
</nav>
<section id="remote-procedure-call-implementation">
<h2><a class="toc-backref" href="#id1" role="doc-backlink">Remote Procedure Call Implementation</a><a class="headerlink" href="#remote-procedure-call-implementation" title="Link to this heading">¶</a></h2>
<p>Traditionally, the C library abstracts over several functions that interface
with the platform’s operating system through system calls. The GPU however does
not provide an operating system that can handle target dependent operations.
Instead, we implemented remote procedure calls to interface with the host’s
operating system while executing on a GPU.</p>
<p>We implemented remote procedure calls using unified virtual memory to create a
shared communicate channel between the two processes. This memory is often
pinned memory that can be accessed asynchronously and atomically by multiple
processes simultaneously. This support means that we can simply provide mutual
exclusion on a shared buffer to swap work back and forth between the host system
and the GPU. We can then use this to create a simple client-server protocol
using this shared memory.</p>
<p>This work treats the GPU as a client and the host as a server. The client
initiates a communication while the server listens for them. In order to
communicate between the host and the device, we simply maintain a buffer of
memory and two mailboxes. One mailbox is write-only while the other is
read-only. This exposes three primitive operations: using the buffer, giving
away ownership, and waiting for ownership. This is implemented as a half-duplex
transmission channel between the two sides. We decided to assign ownership of
the buffer to the client when the inbox and outbox bits are equal and to the
server when they are not.</p>
<p>In order to make this transmission channel thread-safe, we abstract ownership of
the given mailbox pair and buffer around a port, effectively acting as a lock
and an index into the allocated buffer slice. The server and device have
independent locks around the given port. In this scheme, the buffer can be used
to communicate intent and data generically with the server. We then simply
provide multiple copies of this protocol and expose them as multiple ports.</p>
<p>If this were simply a standard CPU system, this would be sufficient. However,
GPUs have my unique architectural challenges. First, GPU threads execute in
lock-step with each other in groups typically called warps or wavefronts. We
need to target the smallest unit of independent parallelism, so the RPC
interface needs to handle an entire group of threads at once. This is done by
increasing the size of the buffer and adding a thread mask argument so the
server knows which threads are active when it handles the communication. Second,
GPUs generally have no forward progress guarantees. In order to guarantee we do
not encounter deadlocks while executing it is required that the number of ports
matches the maximum amount of hardware parallelism on the device. It is also
very important that the thread mask remains consistent while interfacing with
the port.</p>
<a class="reference internal image-reference" href="../_images/rpc-diagram.svg"><img alt="../_images/rpc-diagram.svg" class="align-center" src="../_images/rpc-diagram.svg" width="75%" /></a>
<p>The above diagram outlines the architecture of the RPC interface. For clarity
the following list will explain the operations done by the client and server
respectively when initiating a communication.</p>
<p>First, a communication from the perspective of the client:</p>
<ul class="simple">
<li><p>The client searches for an available port and claims the lock.</p></li>
<li><p>The client checks that the port is still available to the current device and
continues if so.</p></li>
<li><p>The client writes its data to the fixed-size packet and toggles its outbox.</p></li>
<li><p>The client waits until its inbox matches its outbox.</p></li>
<li><p>The client reads the data from the fixed-size packet.</p></li>
<li><p>The client closes the port and continues executing.</p></li>
</ul>
<p>Now, the same communication from the perspective of the server:</p>
<ul class="simple">
<li><p>The server searches for an available port with pending work and claims the
lock.</p></li>
<li><p>The server checks that the port is still available to the current device.</p></li>
<li><p>The server reads the opcode to perform the expected operation, in this
case a receive and then send.</p></li>
<li><p>The server reads the data from the fixed-size packet.</p></li>
<li><p>The server writes its data to the fixed-size packet and toggles its outbox.</p></li>
<li><p>The server closes the port and continues searching for ports that need to be
serviced</p></li>
</ul>
<p>This architecture currently requires that the host periodically checks the RPC
server’s buffer for ports with pending work. Note that a port can be closed
without waiting for its submitted work to be completed. This allows us to model
asynchronous operations that do not need to wait until the server has completed
them. If an operation requires more data than the fixed size buffer, we simply
send multiple packets back and forth in a streaming fashion.</p>
<section id="client-example">
<h3><a class="toc-backref" href="#id2" role="doc-backlink">Client Example</a><a class="headerlink" href="#client-example" title="Link to this heading">¶</a></h3>
<p>The Client API is not currently exported by the LLVM C library. This is
primarily due to being written in C++ and relying on internal data structures.
It uses a simple send and receive interface with a fixed-size packet. The
following example uses the RPC interface to call a function pointer on the
server.</p>
<p>This code first opens a port with the given opcode to facilitate the
communication. It then copies over the argument struct to the server using the
<code class="docutils literal notranslate"><span class="pre">send_n</span></code> interface to stream arbitrary bytes. The next send operation provides
the server with the function pointer that will be executed. The final receive
operation is a no-op and simply forces the client to wait until the server is
done. It can be omitted if asynchronous execution is desired.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"> </span><span class="nf">rpc_host_call</span><span class="p">(</span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">fn</span><span class="p">,</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="kt">size_t</span><span class="w"> </span><span class="n">size</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">rpc</span><span class="o">::</span><span class="n">Client</span><span class="o">::</span><span class="n">Port</span><span class="w"> </span><span class="n">port</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rpc</span><span class="o">::</span><span class="n">client</span><span class="p">.</span><span class="n">open</span><span class="o">&lt;</span><span class="n">RPC_HOST_CALL</span><span class="o">&gt;</span><span class="p">();</span>
<span class="w">  </span><span class="n">port</span><span class="p">.</span><span class="n">send_n</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="p">);</span>
<span class="w">  </span><span class="n">port</span><span class="p">.</span><span class="n">send</span><span class="p">([</span><span class="o">=</span><span class="p">](</span><span class="n">rpc</span><span class="o">::</span><span class="n">Buffer</span><span class="w"> </span><span class="o">*</span><span class="n">buffer</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">buffer</span><span class="o">-&gt;</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="kt">uintptr_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">fn</span><span class="p">);</span>
<span class="w">  </span><span class="p">});</span>
<span class="w">  </span><span class="n">port</span><span class="p">.</span><span class="n">recv</span><span class="p">([](</span><span class="n">rpc</span><span class="o">::</span><span class="n">Buffer</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="w"> </span><span class="p">{});</span>
<span class="w">  </span><span class="n">port</span><span class="p">.</span><span class="n">close</span><span class="p">();</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="server-example">
<h3><a class="toc-backref" href="#id3" role="doc-backlink">Server Example</a><a class="headerlink" href="#server-example" title="Link to this heading">¶</a></h3>
<p>This example shows the server-side handling of the previous client example. When
the server is checked, if there are any ports with pending work it will check
the opcode and perform the appropriate action. In this case, the action is to
call a function pointer provided by the client.</p>
<p>In this example, the server simply runs forever in a separate thread for
brevity’s sake. Because the client is a GPU potentially handling several threads
at once, the server needs to loop over all the active threads on the GPU. We
abstract this into the <code class="docutils literal notranslate"><span class="pre">lane_size</span></code> variable, which is simply the device’s warp
or wavefront size. The identifier is simply the threads index into the current
warp or wavefront. We allocate memory to copy the struct data into, and then
call the given function pointer with that copied data. The final send simply
signals completion and uses the implicit thread mask to delete the temporary
data.</p>
<div class="highlight-c++ notranslate"><div class="highlight"><pre><span></span><span class="k">for</span><span class="p">(;;)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">auto</span><span class="w"> </span><span class="n">port</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">server</span><span class="p">.</span><span class="n">try_open</span><span class="p">(</span><span class="n">index</span><span class="p">);</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">port</span><span class="p">)</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="k">continue</span><span class="p">;</span>

<span class="w">  </span><span class="k">switch</span><span class="p">(</span><span class="n">port</span><span class="o">-&gt;</span><span class="n">get_opcode</span><span class="p">())</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">case</span><span class="w"> </span><span class="no">RPC_HOST_CALL</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">sizes</span><span class="p">[</span><span class="n">LANE_SIZE</span><span class="p">];</span>
<span class="w">    </span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">args</span><span class="p">[</span><span class="n">LANE_SIZE</span><span class="p">];</span>
<span class="w">    </span><span class="n">port</span><span class="o">-&gt;</span><span class="n">recv_n</span><span class="p">(</span><span class="n">args</span><span class="p">,</span><span class="w"> </span><span class="n">sizes</span><span class="p">,</span><span class="w"> </span><span class="p">[</span><span class="o">&amp;</span><span class="p">](</span><span class="kt">uint64_t</span><span class="w"> </span><span class="n">size</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="kt">char</span><span class="p">[</span><span class="n">size</span><span class="p">];</span><span class="w"> </span><span class="p">});</span>
<span class="w">    </span><span class="n">port</span><span class="o">-&gt;</span><span class="n">recv</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">rpc</span><span class="o">::</span><span class="n">Buffer</span><span class="w"> </span><span class="o">*</span><span class="n">buffer</span><span class="p">,</span><span class="w"> </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">id</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="kt">void</span><span class="w"> </span><span class="p">(</span><span class="o">*</span><span class="p">)(</span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="o">&gt;</span><span class="p">(</span><span class="n">buffer</span><span class="o">-&gt;</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">])(</span><span class="n">args</span><span class="p">[</span><span class="n">id</span><span class="p">]);</span>
<span class="w">    </span><span class="p">});</span>
<span class="w">    </span><span class="n">port</span><span class="o">-&gt;</span><span class="n">send</span><span class="p">([</span><span class="o">&amp;</span><span class="p">](</span><span class="n">rpc</span><span class="o">::</span><span class="n">Buffer</span><span class="w"> </span><span class="o">*</span><span class="p">,</span><span class="w"> </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">id</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="k">delete</span><span class="p">[]</span><span class="w"> </span><span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="kt">uint8_t</span><span class="w"> </span><span class="o">*&gt;</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="n">id</span><span class="p">]);</span>
<span class="w">    </span><span class="p">});</span>
<span class="w">    </span><span class="k">break</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="k">default</span><span class="o">:</span>
<span class="w">    </span><span class="n">port</span><span class="o">-&gt;</span><span class="n">recv</span><span class="p">([](</span><span class="n">rpc</span><span class="o">::</span><span class="n">Buffer</span><span class="w"> </span><span class="o">*</span><span class="p">)</span><span class="w"> </span><span class="p">{});</span>
<span class="w">    </span><span class="k">break</span><span class="p">;</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="cuda-server-example">
<h3><a class="toc-backref" href="#id4" role="doc-backlink">CUDA Server Example</a><a class="headerlink" href="#cuda-server-example" title="Link to this heading">¶</a></h3>
<p>The following code shows an example of using the exported RPC interface along
with the C library to manually configure a working server using the CUDA
language. Other runtimes can use the presence of the <code class="docutils literal notranslate"><span class="pre">__llvm_rpc_client</span></code>
in the GPU executable as an indicator for whether or not the server can be
checked. These details should ideally be handled by the GPU language runtime,
but the following example shows how it can be used by a standard user.</p>
<div class="highlight-cuda notranslate" id="libc-gpu-cuda-server"><div class="highlight"><pre><span></span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cstdio&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cstdlib&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;cuda_runtime.h&gt;</span>

<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;shared/rpc.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;shared/rpc_opcodes.h&gt;</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;shared/rpc_server.h&gt;</span>

<span class="p">[[</span><span class="k">noreturn</span><span class="p">]]</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">handle_error</span><span class="p">(</span><span class="n">cudaError_t</span><span class="w"> </span><span class="n">err</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;CUDA error: %s</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">cudaGetErrorString</span><span class="p">(</span><span class="n">err</span><span class="p">));</span>
<span class="w">  </span><span class="n">exit</span><span class="p">(</span><span class="n">EXIT_FAILURE</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// Routes the library symbol into the CUDA runtime interface.</span>
<span class="p">[[</span><span class="n">gnu</span><span class="o">::</span><span class="n">weak</span><span class="p">]]</span><span class="w"> </span><span class="kt">__device__</span><span class="w"> </span><span class="n">rpc</span><span class="o">::</span><span class="n">Client</span><span class="w"> </span><span class="n">client</span><span class="w"> </span><span class="k">asm</span><span class="p">(</span><span class="s">&quot;__llvm_rpc_client&quot;</span><span class="p">);</span>

<span class="c1">// The device-side overload of the standard C function to call.</span>
<span class="k">extern</span><span class="w"> </span><span class="s">&quot;C&quot;</span><span class="w"> </span><span class="kt">__device__</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">puts</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">char</span><span class="w"> </span><span class="o">*</span><span class="p">);</span>

<span class="c1">// Calls the C library function from the GPU C library.</span>
<span class="kr">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">hello</span><span class="p">()</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">puts</span><span class="p">(</span><span class="s">&quot;Hello world!&quot;</span><span class="p">);</span><span class="w"> </span><span class="p">}</span>

<span class="kt">int</span><span class="w"> </span><span class="n">main</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">rpc_client</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">nullptr</span><span class="p">;</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">cudaError_t</span><span class="w"> </span><span class="n">err</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cudaGetSymbolAddress</span><span class="p">(</span><span class="o">&amp;</span><span class="n">rpc_client</span><span class="p">,</span><span class="w"> </span><span class="n">client</span><span class="p">))</span>
<span class="w">    </span><span class="n">handle_error</span><span class="p">(</span><span class="n">err</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Initialize the RPC client and server interface.</span>
<span class="w">  </span><span class="kt">uint32_t</span><span class="w"> </span><span class="n">warp_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">32</span><span class="p">;</span>
<span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">rpc_buffer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">nullptr</span><span class="p">;</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">cudaError_t</span><span class="w"> </span><span class="n">err</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cudaMallocHost</span><span class="p">(</span>
<span class="w">          </span><span class="o">&amp;</span><span class="n">rpc_buffer</span><span class="p">,</span>
<span class="w">          </span><span class="n">rpc</span><span class="o">::</span><span class="n">Server</span><span class="o">::</span><span class="n">allocation_size</span><span class="p">(</span><span class="n">warp_size</span><span class="p">,</span><span class="w"> </span><span class="n">rpc</span><span class="o">::</span><span class="n">MAX_PORT_COUNT</span><span class="p">)))</span>
<span class="w">    </span><span class="n">handle_error</span><span class="p">(</span><span class="n">err</span><span class="p">);</span>
<span class="w">  </span><span class="n">rpc</span><span class="o">::</span><span class="n">Server</span><span class="w"> </span><span class="nf">server</span><span class="p">(</span><span class="n">rpc</span><span class="o">::</span><span class="n">MAX_PORT_COUNT</span><span class="p">,</span><span class="w"> </span><span class="n">rpc_buffer</span><span class="p">);</span>
<span class="w">  </span><span class="n">rpc</span><span class="o">::</span><span class="n">Client</span><span class="w"> </span><span class="nf">client</span><span class="p">(</span><span class="n">rpc</span><span class="o">::</span><span class="n">MAX_PORT_COUNT</span><span class="p">,</span><span class="w"> </span><span class="n">rpc_buffer</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Initialize the client on the device so it can communicate with the server.</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">cudaError_t</span><span class="w"> </span><span class="n">err</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">rpc_client</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">client</span><span class="p">,</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="n">rpc</span><span class="o">::</span><span class="n">Client</span><span class="p">),</span>
<span class="w">                                   </span><span class="n">cudaMemcpyHostToDevice</span><span class="p">))</span>
<span class="w">    </span><span class="n">handle_error</span><span class="p">(</span><span class="n">err</span><span class="p">);</span>

<span class="w">  </span><span class="n">cudaStream_t</span><span class="w"> </span><span class="n">stream</span><span class="p">;</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">cudaError_t</span><span class="w"> </span><span class="n">err</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cudaStreamCreate</span><span class="p">(</span><span class="o">&amp;</span><span class="n">stream</span><span class="p">))</span>
<span class="w">    </span><span class="n">handle_error</span><span class="p">(</span><span class="n">err</span><span class="p">);</span>

<span class="w">  </span><span class="c1">// Execute the kernel.</span>
<span class="w">  </span><span class="n">hello</span><span class="o">&lt;&lt;&lt;</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">stream</span><span class="o">&gt;&gt;&gt;</span><span class="p">();</span>

<span class="w">  </span><span class="c1">// While the kernel is executing, check the RPC server for work to do.</span>
<span class="w">  </span><span class="c1">// Requires non-blocking CUDA kernels but avoids a separate thread.</span>
<span class="w">  </span><span class="k">do</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">port</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">server</span><span class="p">.</span><span class="n">try_open</span><span class="p">(</span><span class="n">warp_size</span><span class="p">,</span><span class="w"> </span><span class="cm">/*index=*/</span><span class="mi">0</span><span class="p">);</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="o">!</span><span class="n">port</span><span class="p">)</span>
<span class="w">      </span><span class="k">continue</span><span class="p">;</span>

<span class="w">    </span><span class="c1">// Only available in-tree from the &#39;libc&#39; sources.</span>
<span class="w">    </span><span class="n">handle_libc_opcodes</span><span class="p">(</span><span class="o">*</span><span class="n">port</span><span class="p">,</span><span class="w"> </span><span class="n">warp_size</span><span class="p">);</span>
<span class="w">    </span><span class="n">port</span><span class="o">-&gt;</span><span class="n">close</span><span class="p">();</span>
<span class="w">  </span><span class="p">}</span><span class="w"> </span><span class="k">while</span><span class="w"> </span><span class="p">(</span><span class="n">cudaStreamQuery</span><span class="p">(</span><span class="n">stream</span><span class="p">)</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">cudaErrorNotReady</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The above code must be compiled in CUDA’s relocatable device code mode and with
the advanced offloading driver to link in the library. Currently this can be
done with the following invocation. Using LTO avoids the overhead normally
associated with relocatable device code linking. The C library for GPU’s
handling is included through the <code class="docutils literal notranslate"><span class="pre">shared/</span></code> directory. This is not currently
installed as it does not use a stable interface.</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>$&gt;<span class="w"> </span>clang++<span class="w"> </span>-x<span class="w"> </span>cuda<span class="w"> </span>rpc.cpp<span class="w"> </span>--offload-arch<span class="o">=</span>native<span class="w"> </span>-fgpu-rdc<span class="w"> </span>-lcudart<span class="w"> </span><span class="se">\</span>
<span class="w">     </span>-I&lt;install-path&gt;include<span class="w"> </span>-L&lt;install-path&gt;/lib<span class="w"> </span>-Xoffload-linker<span class="w"> </span>-lc<span class="w"> </span><span class="se">\</span>
<span class="w">     </span>-O3<span class="w"> </span>-foffload-lto<span class="w"> </span>-o<span class="w"> </span>hello
$&gt;<span class="w"> </span>./hello
Hello<span class="w"> </span>world!
</pre></div>
</div>
</section>
<section id="extensions">
<h3><a class="toc-backref" href="#id5" role="doc-backlink">Extensions</a><a class="headerlink" href="#extensions" title="Link to this heading">¶</a></h3>
<p>The opcode is a 32-bit integer that must be unique to the requested operation.
All opcodes used by <code class="docutils literal notranslate"><span class="pre">libc</span></code> internally have the character <code class="docutils literal notranslate"><span class="pre">c</span></code> in the most
significant byte. Any other opcode is available for use outside of the <code class="docutils literal notranslate"><span class="pre">libc</span></code>
implementation.</p>
</section>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">libc</a></h1>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Status &amp; Support</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../headers/index.html">Implementation Status</a></li>
<li class="toctree-l1"><a class="reference internal" href="../arch_support.html">Architecture Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../platform_support.html">Platform Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../compiler_support.html">Compiler Support</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Simple Usage</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../getting_started.html">Getting Started</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Usage</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../full_host_build.html">Full Host Build</a></li>
<li class="toctree-l1"><a class="reference internal" href="../full_cross_build.html">Full Cross Build</a></li>
<li class="toctree-l1"><a class="reference internal" href="../overlay_mode.html">Overlay Mode</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">libc for GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../uefi/index.html">libc for UEFI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../configure.html">Configure Options</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Development</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../Maintainers.html">LLVM-libc Maintainers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../build_and_test.html">Building and Testing the libc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dev/index.html">Developer Guides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../porting.html">Bringup on a New OS or Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing.html">Contributing to the libc Project</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Useful Links</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../talks.html">Talks</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/llvm/llvm-project/tree/main/libc">Source Code</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/llvm/llvm-project/labels/libc">Bug Reports</a></li>
<li class="toctree-l1"><a class="reference external" href="https://discourse.llvm.org/c/runtimes/libc">Discourse</a></li>
<li class="toctree-l1"><a class="reference external" href="https://discord.gg/xS7Z362">Join the Discord</a></li>
<li class="toctree-l1"><a class="reference external" href="https://discord.com/channels/636084430946959380/636732994891284500">Discord Channel</a></li>
<li class="toctree-l1"><a class="reference external" href="https://lab.llvm.org/buildbot/#/builders?tags=libc">Buildbot</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="index.html">libc for GPUs</a><ul>
      <li>Previous: <a href="support.html" title="previous chapter">Supported Functions</a></li>
      <li>Next: <a href="testing.html" title="next chapter">Testing the GPU C library</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2011-2025, LLVM Project.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 7.2.6</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 0.7.16</a>
      
      |
      <a href="../_sources/gpu/rpc.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>